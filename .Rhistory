OR_observer_lengths_old <- inputs$dat$lencomp |>
filter(fleet == 9)
OR_observer_lengths_new <- read.csv(file.path(
getwd(),
"Data",
"processed",
"rec_comps",
"or_obs_lengths.csv"
)) |>
filter(year > 2016) |>
select(-X)
colnames(OR_observer_lengths_new) <- colnames_l
OR_observer_lengths <- rbind(OR_observer_lengths_old, OR_observer_lengths_new)
# Nsamp method used for all survey length comps is the old Stewart Hamel method from the 2017 assessment where
# Nsamp = n_trips + 0.0707 * n_fish when n_fish/n_tows < 55 and
# Nsamp = 4.89 * n_trips when n_fish/n_tows >= 55
# Triennial survey - fleet 10
TRI_lengths <- inputs$dat$lencom |>
filter(fleet == 10)
# NWFSC survey - fleet 11
# Provided by Elizabeth
NWFSC_lengths_old <- inputs$dat$lencom |>
filter(fleet == 11)
NWFSC_lengths_new <- read.csv(file.path(
getwd(),
"Data",
"processed",
"NWFSC.Combo_and_Tri_length_comps",
"NWFSC.Combo_length_cm_unsexed_raw_10_74_yelloweye rockfish_groundfish_slope_and_shelf_combination_survey.csv"
)) |>
filter(year > 2016)
colnames(NWFSC_lengths_new) <- colnames_l
NWFSC_lengths <- rbind(NWFSC_lengths_old, NWFSC_lengths_new)
# IPHC ORWA - fleet 12
# IPHC bio data notes:
# Total_Biodata_Comb includes all Yelloweye biodata collected from IPHC FISS 2A
# from 2022-2023 and stlkeys for association with the IPHC effort database, and
# some location information pulled from the IPHC effort database
# Experimental gear catch and catch where species could not be rectified against
# onboard tag documentation were removed.
# 2A was not fished in 2020 and 2024.  Oregon stations were not fished in 2023.
# Oregon rockfish were not tagged in 2021 and fish cannot be reconciled with IPHC
# effort data.
# IPHC has not provided onboard tag information for Oregon stations in 2019. 2019
# landings currently cannot be reconciled with IPHC effort data.
# From the 2017 assessment, it looks like Jason and Vlada used only lengths that also
# had ages EXCEPT for 2016 where they used all the lengths, we will keep their data for this
# year because there were not many samples for this year and only using lengths
# that have ages for 2016 truncates the age data
IPHC_lengths_old <- inputs$dat$lencom |>
filter(fleet == 12)
IPHC_lengths_new <- read.csv(file.path(
getwd(),
"Data",
"processed",
"IPHC_bio_data",
"iphc_length_comps.csv"
)) |>
filter(year > 2016)
colnames(IPHC_lengths_new) <- colnames_l
IPHC_lengths <- rbind(IPHC_lengths_old, IPHC_lengths_new)
# Put all lengths together
all_lengths <- do.call(
"rbind",
list(
CA_TWL_lengths,
CA_NONTWL_lengths,
CA_NONTWL_lengths_wcgop,
CA_REC_lengths,
ORWA_TWL_lengths,
ORWA_NONTWL_lengths,
OR_REC_lengths,
WA_REC_lengths,
CA_observer_lengths,
OR_observer_lengths,
TRI_lengths,
NWFSC_lengths,
IPHC_lengths
)
)
inputs$dat$lencomp <- all_lengths
colnames_a <- colnames(inputs$dat$agecom)
# CA TWL CAAL and MAAL - fleet 1 and -1
CA_TWL_ages <- inputs$dat$agecom |>
filter(fleet %in% c(-1, 1))
# CA_TWL_ages_new <-
# CA_TWL_ages <- rbind(CA_TWL_ages_old, CA_TWL_ages_new)
# CA NONTWL CAAL and MAAL - fleet 2 and -2
# From Juliette
# QUESTION: Where is this dataset?
CA_NONTWL_ages <- inputs$dat$agecom |>
filter(fleet %in% c(-2, 2)) |>
filter(year < 2005)
# CA_NONTWL_ages_new <-
# CA_NONTWL_ages <- rbind(CA_NONTWL_ages_old, CA_NONTWL_ages_new)
# CA NONTWL WCGOP - fleet -2 and 2
CA_NONTWL_ages_wcgop <- inputs$dat$agecom |>
filter(fleet %in% c(-2, 2)) |>
filter(year == 2005)
# CA REC CAAL and MAAL (aged by WDFW, 1983 and 1996 only) - fleet -3 and 3
CA_REC_wdfw <- inputs$dat$agecom |>
filter(fleet %in% c(-3, 3))
CA_REC_wdfw <- CA_REC_wdfw[1:4, ]
# CA REC CAAL and MAAL (data from Don Pearson 1979 - 1984, aged by Betty) - fleet -3 and 3
CA_REC_don_pearson <- inputs$dat$agecom |>
filter(fleet %in% c(-3, 3))
CA_REC_don_pearson <- CA_REC_don_pearson[-c(1:4), ] |>
filter(year < 1985)
# CA REC CAAL and MAAL (data from CDFW Julia Coates) - fleet -3 and 3
# QUESTION: There are no updates to these since 2016?
CA_REC_caal <- inputs$dat$agecomp |>
filter(fleet == 3) |>
filter(year >=2009)
CA_REC_maal <- inputs$dat$agecomp |>
filter(fleet == -3) |>
filter(year >= 2009)
CA_REC_ages <- rbind(CA_REC_caal, CA_REC_maal)
# ORWA TWL CAAL and MAAL (PacFIN and WCGOP combined) - fleet 4 and -4
# Provided by Juliette
# QUESTION: Where is this dataset?
ORWA_TWL_ages <- inputs$dat$agecom |>
filter(fleet %in% c(-4, 4))
# ORWA_TWL_ages_new <-
# ORWA_TWL_ages <- rbind(ORWA_TWL_ages_old, ORWA_TWL_ages_new)
# ORWA NONTWL CAAL and MAAL (PacFIN and WCGOP combined) - fleet 5 and -5
# Provided by Juliette
# QUESTION: Where is this dataset?
ORWA_NONTWL_ages <- inputs$dat$agecom |>
filter(fleet %in% c(-5, 5))
# ORWA_NONTWL_ages_new <-
# ORWA_NONTWL_ages <- rbind(ORWA_NONTWL_ages_old, ORWA_NONTWL_ages_new)
# OR REC CAAL and MAAL - fleet -6 and 6
# Morgan and Abby need to provide an updated data set
# Do we only have these up until 2016 still?
OR_REC_caal_old <- inputs$dat$agecom |>
filter(fleet == 6)
OR_REC_caal_new <- read.csv(file.path(
getwd(),
"Data",
"processed",
"rec_comps",
"or_rec_caal.csv"
)) |>
filter(year > 2016)
colnames(OR_REC_caal_new) <- colnames_a
OR_REC_caal <- rbind(OR_REC_caal_old, OR_REC_caal_new)
OR_REC_maal_old <- inputs$dat$agecom |>
filter(fleet == -6)
OR_REC_maal_new <- read.csv(file.path(
getwd(),
"Data",
"processed",
"rec_comps",
"or_rec_maal.csv"
))|>
filter(year > 2016) |>
select(-X)
colnames(OR_REC_maal_new) <- colnames_a
OR_REC_maal <- rbind(OR_REC_maal_old, OR_REC_maal_new)
OR_REC_ages <- rbind(OR_REC_caal, OR_REC_maal)
# WA REC CAAL and MAAL - fleet -7 and 7
# Provided by Morgan and Abby
# Fabio said to use new ages because they have been reanalyzed
WA_REC_caal <- read.csv(file.path(
getwd(),
"Data",
"processed",
"rec_comps",
"wa_rec_caal.csv"
))
colnames(WA_REC_caal) <- colnames_a
WA_REC_maal <- read.csv(file.path(
getwd(),
"Data",
"processed",
"rec_comps",
"wa_rec_maal.csv"
))
colnames(WA_REC_maal) <- colnames_a
WA_REC_ages <- rbind(WA_REC_caal, WA_REC_maal)
# Nsamp method used for all survey maal is the old Stewart Hamel method from the 2017 assessment where
# Nsamp = n_trips + 0.0707 * n_fish when n_fish/n_tows < 55 and
# Nsamp = 4.89 * n_trips when n_fish/n_tows >= 55
# NWFSC survey CAAL and MAAL - fleet -11 and 11
# QUESTION: The age comps were a little different between the old assessment and the new assessment, are we
# going to use updated ages? for all years?
# NWFSC_caal_old <- inputs$dat$agecom |>
#   filter(fleet == 11)
NWFSC_caal_new <- read.csv(file.path(
getwd(),
"Data",
"processed",
"NWFSC.Combo_CAAL",
"processed_one_sex_caal.csv"
))
# |>
#   filter(year > 2016)
colnames(NWFSC_caal_new) <- colnames_a
NWFSC_caal <- NWFSC_caal_new
# NWFSC_caal <- rbind(NWFSC_caal_old, NWFSC_caal_new)
# NWFSC_maal_old <- inputs$dat$agecom |>
#   filter(fleet == -11)
NWFSC_maal_new <- read.csv(file.path(
getwd(),
"Data",
"processed",
"NWFSC.Combo_age_comps",
"NWFSC.Combo_age_unsexed_raw_0_65_yelloweye rockfish_groundfish_slope_and_shelf_combination_survey.csv"
)) |>
mutate(
ageerr = 2,
fleet = -11
)
# |>
#   filter(year > 2016)
colnames(NWFSC_maal_new) <- colnames_a
NWFSC_maal <- NWFSC_maal_new
# NWFSC_maal <- rbind(NWFSC_maal_old, NWFSC_maal_new)
NWFSC_ages <- rbind(NWFSC_caal, NWFSC_maal)
# IPHC survey CAAL and MAAL - fleet -12 and 12
# Data provided by Fabio, bio comps processed by Elizabeth
IPHC_caal_old <- inputs$dat$agecom |>
filter(fleet == 12) |>
filter(year <= 2016)
IPHC_caal_new <- read.csv(file.path(
getwd(),
"Data",
"processed",
"IPHC_bio_data",
"iphc_caal.csv"
)) |>
filter(year > 2016)
colnames(IPHC_caal_new) <- colnames_a
IPHC_caal <- rbind(IPHC_caal_old, IPHC_caal_new)
IPHC_maal_old <- inputs$dat$agecom |>
filter(fleet == -12) |>
filter(year <= 2016)
IPHC_maal_new <- read.csv(file.path(
getwd(),
"Data",
"processed",
"IPHC_bio_data",
"iphc_marginal_ages.csv"
)) |>
filter(year > 2016)
colnames(IPHC_maal_new) <- colnames_a
IPHC_maal <- rbind(IPHC_maal_old, IPHC_maal_new)
IPHC_ages <- rbind(IPHC_caal, IPHC_maal)
# Combine all ages together
all_ages <- do.call(
"rbind",
list(
CA_TWL_ages,
CA_NONTWL_ages,
CA_NONTWL_ages_wcgop,
CA_REC_wdfw,
CA_REC_don_pearson,
CA_REC_ages,
ORWA_TWL_ages,
ORWA_NONTWL_ages,
OR_REC_ages,
WA_REC_ages,
NWFSC_ages,
IPHC_ages
)
)
inputs$dat$agecomp <- all_ages
r4ss::SS_write(inputs, dir = here::here("model/2025_update_all_data"), overwrite = TRUE)
# Get inputs from 2017 assessment that will get carried over to this assessment
# You can also change this to another model
model_2025_path <- file.path(getwd(), "model", "2025_update_all_data")
ctl <- r4ss::SS_readctl(file = file.path(model_2025_path, "yelloweye_control.ss"))
inputs <- r4ss::SS_read(file = file.path(model_2025_path, "yelloweye_control.ss"))
inputs <- r4ss::SS_read(file = model_2025_path)
inputs <- r4ss::SS_read(model_2025_path)
ctl <- inputs$ctl
library(dplyr)
library(tidyr)
library(r4ss)
# Get inputs from 2017 assessment that will get carried over to this assessment
# You can also change this to another model
model_2025_path <- file.path(getwd(), "model", "2025_update_all_data")
inputs <- r4ss::SS_read(model_2025_path)
ctl <- inputs$ctl
ctl$Block_Design[[2]][2] <- 2024
ctl$Block_Design[[3]][2] <- 2024
ctl$Block_Design[[4]][2] <- 2024
ctl$MG_parms["Wtlen_1_Fem_GP_1",]$INIT <- 7.183309e-06
ctl$MG_parms["Wtlen_1_Fem_GP_1",]$PRIOR <- 7.183309e-06
ctl$MG_parms["Wtlen_2_Fem_GP_1",]$INIT <- 3.244801
ctl$MG_parms["Wtlen_2_Fem_GP_1",]$PRIOR <-3.244801
# Change last year of main rec_dev, for the last assessment this was 2015 so I
# would assume this would be 2023 for this year?
ctl$MainRdevYrLast <- 2023
# Fill outfile with directory and file name of the file written
r4ss::SS_writectl(ctl, outfile = file.path(model_2025_path, "yelloweye_control.ss"), overwrite = TRUE)
r4ss::get_ss3_exe(dir = model_2025_path)
devtools::install_github('r4ss/r4ss')
unloadNamespace("r4ss")
devtools::install_github('r4ss/r4ss')
.libPaths()
unloadNamespace("xfun")
unloadNamespace("knitr")
unloadNamespace("kableExtra")
unloadNamespace("xfun")
unloadNamespace("knitr")
unloadNamespace("rmarkdown")
unloadNamespace("knitr")
unloadNamespace("xfun")
devtools::unload("xfun")
test <- inputs$dat$catch
testing <- inputs$dat$catch %>%
filter(fleet == 1, year == 2024)
rm(list=ls())
library(dplyr)
library(tidyr)
library(ggplot2)
#remotes::install_github("r4ss/r4ss")
library(r4ss)
library(readr)
library(nwfscSurvey)
library(here)
#remotes::install_github("pfmc-assessments/pacfintools")
library(pacfintools)
exe_loc <- here::here('model/ss3.exe')
updated_startfile_dir <- here::here("model", "updated_alldata_tunecomps_fitbias_ctl_tunecomps_start_20250512")
base_comm_discards_updated_dir <- here::here("model", "base_comm_discards_updated")
copy_SS_inputs(
dir.old = updated_startfile_dir,
dir.new = base_comm_discards_updated_dir,
create.dir = TRUE,
overwrite = TRUE,
use_ss_new = TRUE,
verbose = TRUE
)
#all catch
inputs <- SS_read(dir = file.path(getwd(), "model", "base_comm_discards_updated"))
catch <- inputs$dat$catch
View(catch)
testing <- inputs$dat$catch %>%
filter(fleet == 2, year == 2024)
View(testing)
discards_1 <- discards_all_ave_2021to2023$avg_discards[discards_all_ave_2021to2023$ST_FLEET == "CA_TWL"]
# read in commercial discards
discards <- read.csv(file.path(getwd(),"Data","processed","discards","commercial_discards.csv")) |>
# remove column of row names from previous save
dplyr::select(-X)
# Combine OR and WA discards for fleet
discards_ORWA <- discards |>
dplyr::filter(grepl("OR|WA", fleet)) |>
tidyr::separate_wider_delim(fleet, delim = "-", names = c("fleet", "state")) |>
dplyr::group_by(year, fleet) |>
dplyr::summarise(discards = sum(total_discards)) |>
dplyr::ungroup() |>
dplyr::mutate(state = "ORWA")
# Combine CA and ORWA discards into final discards df
discards_all <- discards |>
dplyr::filter(grepl("CA", fleet)) |>
tidyr::separate_wider_delim(fleet, delim = "-", names = c("fleet", "state")) |>
dplyr::rename(discards = total_discards) |>
rbind(discards_ORWA) |>
dplyr::mutate(ST_FLEET = glue::glue("{state}_{fleet}")) |>
dplyr::select(-c(fleet, state)) |>
dplyr::filter(year > 2015)
discards_all_ave_2021to2023 <- discards_all %>%
filter(year %in% c(2021, 2022, 2023)) %>%
group_by(ST_FLEET) %>%
summarise(avg_discards = mean(discards, na.rm = TRUE, .groups = "drop"))
discards_1 <- discards_all_ave_2021to2023$avg_discards[discards_all_ave_2021to2023$ST_FLEET == "CA_TWL"]
discards_1
discards_2 <- discards_all_ave_2021to2023$avg_discards[discards_all_ave_2021to2023$ST_FLEET == "CA_NONTWL"]
discards_3 <- discards_all_ave_2021to2023$avg_discards[discards_all_ave_2021to2023$ST_FLEET == "ORWA_TWL"]
discards_4 <- discards_all_ave_2021to2023$avg_discards[discards_all_ave_2021to2023$ST_FLEET == "ORWA_NONTWL"]
discards_2
discards_3
discards_4
updated_startfile_dir <- here::here("model", "updated_alldata_tunecomps_fitbias_ctl_tunecomps_start_20250512")
base_comm_discards_updated_dir <- here::here("model", "base_comm_discards_updated")
copy_SS_inputs(
dir.old = updated_startfile_dir,
dir.new = base_comm_discards_updated_dir,
create.dir = TRUE,
overwrite = TRUE,
use_ss_new = TRUE,
verbose = TRUE
)
#all catch
inputs <- SS_read(dir = file.path(getwd(), "model", "base_comm_discards_updated"))
catch <- inputs$dat$catch
# read in commercial discards
discards <- read.csv(file.path(getwd(),"Data","processed","discards","commercial_discards.csv")) |>
# remove column of row names from previous save
dplyr::select(-X)
# Combine OR and WA discards for fleet
discards_ORWA <- discards |>
dplyr::filter(grepl("OR|WA", fleet)) |>
tidyr::separate_wider_delim(fleet, delim = "-", names = c("fleet", "state")) |>
dplyr::group_by(year, fleet) |>
dplyr::summarise(discards = sum(total_discards)) |>
dplyr::ungroup() |>
dplyr::mutate(state = "ORWA")
# Combine CA and ORWA discards into final discards df
discards_all <- discards |>
dplyr::filter(grepl("CA", fleet)) |>
tidyr::separate_wider_delim(fleet, delim = "-", names = c("fleet", "state")) |>
dplyr::rename(discards = total_discards) |>
rbind(discards_ORWA) |>
dplyr::mutate(ST_FLEET = glue::glue("{state}_{fleet}")) |>
dplyr::select(-c(fleet, state)) |>
dplyr::filter(year > 2015)
discards_all_ave_2021to2023 <- discards_all %>%
filter(year %in% c(2021, 2022, 2023)) %>%
group_by(ST_FLEET) %>%
summarise(avg_discards = mean(discards, na.rm = TRUE, .groups = "drop"))
discards_1 <- discards_all_ave_2021to2023$avg_discards[discards_all_ave_2021to2023$ST_FLEET == "CA_TWL"]
discards_2 <- discards_all_ave_2021to2023$avg_discards[discards_all_ave_2021to2023$ST_FLEET == "CA_NONTWL"]
discards_4 <- discards_all_ave_2021to2023$avg_discards[discards_all_ave_2021to2023$ST_FLEET == "ORWA_TWL"]
discards_5 <- discards_all_ave_2021to2023$avg_discards[discards_all_ave_2021to2023$ST_FLEET == "ORWA_NONTWL"]
inputs$dat$catch <- inputs$dat$catch %>%
mutate(catch = if_else(fleet == 1 & year == 2024, catch + discards_1, catch)) %>%
mutate(catch = if_else(fleet == 2 & year == 2024, catch + discards_2, catch)) %>%
mutate(catch = if_else(fleet == 4 & year == 2024, catch + discards_4, catch)) %>%
mutate(catch = if_else(fleet == 5 & year == 2024, catch + discards_5, catch))
test <- inputs$dat$catch
View(test)
updated_startfile_dir <- here::here("model", "updated_alldata_tunecomps_fitbias_ctl_tunecomps_start_20250512")
base_comm_discards_updated_dir <- here::here("model", "base_comm_discards_updated")
copy_SS_inputs(
dir.old = updated_startfile_dir,
dir.new = base_comm_discards_updated_dir,
create.dir = TRUE,
overwrite = TRUE,
use_ss_new = TRUE,
verbose = TRUE
)
#all catch
inputs <- SS_read(dir = file.path(getwd(), "model", "base_comm_discards_updated"))
# read in commercial discards
discards <- read.csv(file.path(getwd(),"Data","processed","discards","commercial_discards.csv")) |>
# remove column of row names from previous save
dplyr::select(-X)
# Combine OR and WA discards for fleet
discards_ORWA <- discards |>
dplyr::filter(grepl("OR|WA", fleet)) |>
tidyr::separate_wider_delim(fleet, delim = "-", names = c("fleet", "state")) |>
dplyr::group_by(year, fleet) |>
dplyr::summarise(discards = sum(total_discards)) |>
dplyr::ungroup() |>
dplyr::mutate(state = "ORWA")
# Combine CA and ORWA discards into final discards df
discards_all <- discards |>
dplyr::filter(grepl("CA", fleet)) |>
tidyr::separate_wider_delim(fleet, delim = "-", names = c("fleet", "state")) |>
dplyr::rename(discards = total_discards) |>
rbind(discards_ORWA) |>
dplyr::mutate(ST_FLEET = glue::glue("{state}_{fleet}")) |>
dplyr::select(-c(fleet, state)) |>
dplyr::filter(year > 2015)
discards_all_ave_2021to2023 <- discards_all %>%
filter(year %in% c(2021, 2022, 2023)) %>%
group_by(ST_FLEET) %>%
summarise(avg_discards = mean(discards, na.rm = TRUE, .groups = "drop"))
discards_1 <- discards_all_ave_2021to2023$avg_discards[discards_all_ave_2021to2023$ST_FLEET == "CA_TWL"]
discards_2 <- discards_all_ave_2021to2023$avg_discards[discards_all_ave_2021to2023$ST_FLEET == "CA_NONTWL"]
discards_4 <- discards_all_ave_2021to2023$avg_discards[discards_all_ave_2021to2023$ST_FLEET == "ORWA_TWL"]
discards_5 <- discards_all_ave_2021to2023$avg_discards[discards_all_ave_2021to2023$ST_FLEET == "ORWA_NONTWL"]
inputs$dat$catch <- inputs$dat$catch %>%
mutate(catch = if_else(fleet == 1 & year == 2024, catch + discards_1, catch)) %>%
mutate(catch = if_else(fleet == 2 & year == 2024, catch + discards_2, catch)) %>%
mutate(catch = if_else(fleet == 4 & year == 2024, catch + discards_4, catch)) %>%
mutate(catch = if_else(fleet == 5 & year == 2024, catch + discards_5, catch))
SS_write(inputs, dir = file.path(getwd(), "model", "base_comm_discards_updated"), overwrite = TRUE)
get_ss3_exe(dir = file.path(getwd(), "model", "base_comm_discards_updated"))
run(dir = file.path(getwd(), "model", "base_comm_discards_updated"), show_in_console = TRUE)
rm(list=ls())
library(dplyr)
library(tidyr)
library(ggplot2)
#remotes::install_github("r4ss/r4ss")
library(r4ss)
library(readr)
library(nwfscSurvey)
library(here)
#remotes::install_github("pfmc-assessments/pacfintools")
library(pacfintools)
exe_loc <- here::here('model/ss3.exe')
base_comm_discards_updated_dir <- here::here("model", "base_comm_discards_updated")
base_comm_discards_steepness_updated_dir <- here::here("model", "base_comm_discards_steepness_updated")
copy_SS_inputs(
dir.old = base_comm_discards_updated_dir,
dir.new = base_comm_discards_steepness_updated_dir,
create.dir = TRUE,
overwrite = TRUE,
use_ss_new = TRUE,
verbose = TRUE
)
inputs <- SS_read(dir = base_comm_discards_steepness_updated_dir)
inputs$ctl$SR_parms$INIT[2] <- 0.72
inputs$ctl$SR_parms$PRIOR[2] <- 0.72
ctl <- inputs$ctl
# Fill outfile with directory and file name of the file written
r4ss::SS_writectl(
ctl,
outfile = file.path(base_comm_discards_steepness_updated_dir, "yelloweye_control.ss"),
overwrite = TRUE
)
r4ss::get_ss3_exe(dir = base_comm_discards_steepness_updated_dir)
# You have to run this model in full (not using -nohess) because you need the covar file
# to fit the bias
r4ss::run(dir = base_comm_discards_steepness_updated_dir, show_in_console = TRUE)
replist_base_comm_discards_steepness_updated_dir <- r4ss::SS_output(dir = base_comm_discards_steepness_updated_dir)
r4ss::SS_plots(replist_base_comm_discards_steepness_updated_dir)
