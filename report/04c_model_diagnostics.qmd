## Model Diagnostics

<!-- If a range of model runs is used to characterize uncertainty, it is important to provide some qualitative or quantitative information about relative probability of each. If no statements about relative probability can be made, then it is important to state that all scenarios (or all scenarios between the bounds depicted by the runs) are equally likely.  
If possible, ranges depicting uncertainty should include at least three runs: (a) one judged most probable; (b) at least one that depicts the range of uncertainty in the direction of lower current biomass levels; and (c) one that depicts the range of uncertainty in the direction of higher current biomass levels. The entire range of uncertainty should be carried through stock projections and decision table analyses.  -->

### Convergence

<!-- Convergence status and convergence criteria for the base-run model (or proposed base run). Randomization of starting parameter value run (e.g., jitter) results or other evidence of search for global best estimates.  -->

### Sensitivity Analyses

#### Sensitivity to assumptions about model structure

Sensitivity analysis to examine the impact of different assumptions about model structure on management quantities included a model with an estimated baseline Natural Mortality rate (M), one with estimated steepness (h) of the stock-recruit relationship, and one using the 2017 length-weight relationship. 

The Natural Mortality rate (M) estimated by the first model was higher than that of the base model (~ 0.055 $year^-1$ compared to ~ 0.044 $year^-1$ from the base model). The second model estimated steepness at a higher value of ~ 0.905, which indicates recruitment is more dependent on spawning stock biomass, as opposed from the fixed value of 0.718 from the base model.

As shown in **Figure X** to **Figure X**, the base model is considerably sensitive to whether the Natural Mortality rate is estimated or fixed, with the alternative model estimating a higher spawning output compared to the base model. Similar outcomes are shown for the model with estimated steepness, which estimated a higher spawning output compared to the base model. Contrastingly, outputs of the model using the 2017 length-weight relationship showed the base model is not sensititive to this modelling choice, with very similar spawning outputs between the base and alternative model (**Figure X** to **Figure X**).   

#### Sensitivity to data set choice and weighting schemes

<!-- Sensitivity to data set choice (e.g., using emphasis factors to selectively remove data sources) and weighting schemes (e.g., MacAllister & Ianelli weighting versus Francis weighting vs. Dirichlet weighting for compositional data), which may also include a consideration of recent patterns in recruitment.  -->
 
### Retrospective Analysis

<!-- Retrospective analysis, where the model is fitted to a series of shortened input data sets, with the most recent years of input data being dropped.  -->
 
<!-- Historical analysis (plot of actual estimates from current and previous assessments).  -->

### Likelihood Profiles

<!-- Evaluation of model parameters. Likelihood profile for the base model over key parameters (typically natural morality, stock-recruit steepness, and equilibrium recruitment, or R0). The profile should indicate all likelihood values for individual components (e.g., indices by survey, compositional data for each type and fleet).   -->

## Unresolved Problems and Major Uncertainties

<!-- Describe any special issues (e.g., unbalanced or questionable data, missing survey data) that complicate scientific assessment, questions about the best model scenario. -->
